{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784812c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Befehle, die verschiedene Funktionen von Spacy laden. Basis für die Programmierung.\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d61cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x2492dcae640>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Englisches Sprachpaket small und Spacytextblobpipe auf nlp laden\n",
    "nlp = spacy.load ('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f703ee98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The club isn't the best place to find a lover So the bar is where I go Me and my friends at the table doing shots Drinking fast and then we talk slow And you come over and start up a conversation with just me And trust me I'll give it a chance now Take my hand stop put Van the Man on the jukebox And then we start to dance and now I'm singing like Girl you know I want your love Your love was handmade for somebody like me Come on now follow my lead I may be crazy don't mind me Say boy let's not talk too much Grab on my waist and put that body on me Come on now follow my lead Come come on now follow my lead I'm in love with the shape of you We push and pull like a magnet do Although my heart is falling too I'm in love with your body And last night you were in my room And now my bedsheets smell like you Every day discovering something brand new I'm in love with your body Oh-I-oh-I-oh-I-oh-I I'm in love with your body Oh-I-oh-I-oh-I-oh-I I'm in love with your body Oh-I-oh-I-oh-I-oh-I I'm in love with your body Every day discovering something brand new I'm in love with the shape of you One week in we let the story begin We're going out on our first date You and me are thrifty so go all you can eat Fill up your bag and I fill up a plate We talk for hours and hours about the sweet and the sour And how your family is doing okay Leave and get in a taxi then kiss in the backseat Tell the driver make the radio play and I'm singing like Girl you know I want your love Your love was handmade for somebody like me Come on now follow my lead I may be crazy don't mind me Say boy let's not talk too much Grab on my waist and put that body on me Come on now follow my lead Come come on now follow my lead I'm in love with the shape of you We push and pull like a magnet do Although my heart is falling too I'm in love with your body And last night you were in my room And now my bedsheets smell like you Every day discovering something brand new I'm in love with your body Oh-I-oh-I-oh-I-oh-I I'm in love with your body Oh-I-oh-I-oh-I-oh-I I'm in love with your body Oh-I-oh-I-oh-I-oh-I I'm in love with your body Every day discovering something brand new I'm in love with the shape of you Come on be my baby come on Come on be my baby come on Come on be my baby come on Come on be my baby come on Come on be my baby come on Come on be my baby come on Come on be my baby come on Come on be my baby come on I'm in love with the shape of you We push and pull like a magnet do Although my heart is falling too I'm in love with your body Last night you were in my room And now my bedsheets smell like you Every day discovering something brand new I'm in love with your body Come on be my baby come on Come on be my baby come on I'm in love with your body Come on be my baby come on Come on be my baby come on I'm in love with your body Come on be my baby come on Come on be my baby come on I'm in love with your body Every day discovering something brand new I'm in love with the shape of you\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Textdatei wird eingelesen, Zeilenumbrüche werden entfernt\n",
    "text = open(\"Shape of you - Ed Sheeran.txt\").read()\n",
    "text = text.replace(\"\\n\", \" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba114c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, die den Text normalisiert: Entfernt alle Satz- und Lehrzeichen, wandelt konjugierte Verben in Stammform um.\n",
    "# Gibt am Ende den normalisierten Text zurück. Funktion kann auf jedem beliebigen Text aufgerufen werden\n",
    "\n",
    "def normalize_ws (text):\n",
    "    norm_text = []\n",
    "    for token in text:\n",
    "            if not token.is_punct and not token.is_space:\n",
    "                    norm_text.append(token.lemma_.lower())\n",
    "    return ' '.join(norm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae9f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text wird in Tokenisierten NLP Text umgewandelt\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf140ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das \"DOC\" wird mit dem Funktionsaufruf \"normalize_ws\" normalisiert und abgespeichert\n",
    "normalized_ws_text = normalize_ws(doc)\n",
    "# Das normalisierte DOC muss wieder in einen NLP Text umgewandelt werden\n",
    "normalized_ws_doc = nlp(normalized_ws_text)\n",
    "# Alle Nouns werden aus dem normalisierten Text herausgefiltert:\n",
    "nouns_ws = [ token.text for token in normalized_ws_doc if token.pos_ == 'NOUN']\n",
    "# Alle Nouns werden aus dem normalisierten Text herausgefiltert:\n",
    "verbs_ws = [ token.text for token in normalized_ws_doc if token.pos_ == 'VERB']\n",
    "# Alle Wörter werden als Tokentext abgespeichert\n",
    "words_ws = [ token.text for token in normalized_ws_doc]\n",
    "#Anzahl der Token umgewandelt in String und dann in Token\n",
    "number = len(nlp(normalized_ws_doc)) \n",
    "number = str(number)\n",
    "number = nlp(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc4446fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe zur Kontrolle\n",
    "#print(nouns_ws)\n",
    "#print(verbs_ws)\n",
    "#print(words_ws)\n",
    "#print (doc)\n",
    "#print (normalized_ws_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b078970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der 10 am häufigsten vorkommenden Nouns\n",
    "ten_nouns = Counter(nouns_ws).most_common(10)\n",
    "# Berechnung der 10 am häufigsten vorkommenden Verben\n",
    "ten_verbs = Counter(verbs_ws).most_common(10)\n",
    "#Berechnung der 10 am häufigsten vorkommenden Wörter\n",
    "ten_words = Counter(words_ws).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7328f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays werden initialisiert\n",
    "song_sent_score = []\n",
    "song_sent_label = []\n",
    "song_sent_subjectivity = []\n",
    "total_pos = []\n",
    "total_neg = []\n",
    "positive_words = []\n",
    "negative_words = []\n",
    "\n",
    "#Sentiment und Subjectivity wird dem Lied zugeordnet\n",
    "sentiment = doc._.blob.polarity\n",
    "sentiment = round(sentiment,2)\n",
    "subjectivity = doc._.blob.subjectivity\n",
    "subjectivity = round(subjectivity,2)\n",
    "\n",
    "#Sentimentscore wird verwendet um das Lied als positives oder negatives einzustufen\n",
    "if sentiment > 0:\n",
    "  sent_label = \"Positive\"\n",
    "else:\n",
    "  sent_label = \"Negative\"\n",
    "\n",
    "#Resultate werden den entsprechenden Kategorien zugeordnet\n",
    "song_sent_label.append(sent_label)\n",
    "song_sent_score.append(sentiment)\n",
    "song_sent_subjectivity.append(subjectivity)\n",
    "\n",
    "#Einzelne Tupel (Token + Sentiment) werden als positives oder negatives Wort geteilt\n",
    "for x in doc._.blob.sentiment_assessments.assessments:\n",
    "  if x[1] > 0:\n",
    "    positive_words.append(x[0][0])\n",
    "  elif x[1] < 0:\n",
    "    negative_words.append(x[0][0])\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "#Resultate werden den entsprechenden Kategorien zugeordnet\n",
    "total_pos.append(', '.join(set(positive_words)))\n",
    "total_neg.append(', '.join(set(negative_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39fe8b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fehlende Arrays werden erstellt\n",
    "total_nouns = []\n",
    "total_verbs = []\n",
    "total_words = []\n",
    "total_amount = []\n",
    "\n",
    "#Listen werden mit Panda als Basisdatei eingelesen\n",
    "liste = pd.read_csv(\"liste.csv\", index_col=\"Nr.\")\n",
    "liste1 = pd.read_csv(\"liste1.csv\", index_col=\"Nr.\")\n",
    "\n",
    "#Liste wird mit Daten gefüllt\n",
    "liste [\"Häufigste Nouns\"]= ten_nouns\n",
    "liste [\"Häufigste Verben\"]= ten_verbs\n",
    "liste [\"Häufigste Wörter\"]= ten_words\n",
    "\n",
    "#Liste 1 wird mit Daten gefüllt\n",
    "liste1[\"Anzahl aller Token\"] = number\n",
    "liste1[\"Sentiment Score\"] = song_sent_score\n",
    "liste1[\"Sentiment Label\"] = song_sent_label\n",
    "liste1[\"Sentiment Subjectivity\"] = song_sent_subjectivity\n",
    "liste1[\"Positive Wörter\"] = total_pos\n",
    "liste1[\"Negative Wörter\"] = total_neg\n",
    "\n",
    "\n",
    "#Listen werden als CSV gespeichert\n",
    "liste.to_csv(\"Ergebnisse\\ergebnisse.csv\")\n",
    "liste1.to_csv(\"Ergebnisse\\sentiment.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
