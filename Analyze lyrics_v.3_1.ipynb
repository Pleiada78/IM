{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784812c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Befehle, die verschiedene Funktionen von Spacy laden. Basis für die Programmierung.\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d61cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x1f88a82f610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Englisches Sprachpaket small und Spacytextblobpipe auf nlp laden\n",
    "nlp = spacy.load ('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f703ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Textdatei wird eingelesen, Zeilenumbrüche werden entfernt\n",
    "text = open(\"Shape of you - Ed Sheeran.txt\").read()\n",
    "text = text.replace(\"\\n\", \" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba114c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, die den Text normalisiert: Entfernt alle Satz- und Lehrzeichen, wandelt konjugierte Verben in Stammform um.\n",
    "# Gibt am Ende den normalisierten Text zurück. Funktion kann auf jedem beliebigen Text aufgerufen werden\n",
    "\n",
    "def normalize_ws (text):\n",
    "    norm_text = []\n",
    "    for token in text:\n",
    "            if not token.is_punct and not token.is_space:\n",
    "                    norm_text.append(token.lemma_.lower())\n",
    "    return ' '.join(norm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae9f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text wird in Tokenisierten NLP Text umgewandelt\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf140ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das \"DOC\" wird mit dem Funktionsaufruf \"normalize_ws\" normalisiert und abgespeichert\n",
    "normalized_ws_text = normalize_ws(doc)\n",
    "# Das normalisierte DOC muss wieder in einen NLP Text umgewandelt werden\n",
    "normalized_ws_doc = nlp(normalized_ws_text)\n",
    "# Alle Nouns werden aus dem normalisierten Text herausgefiltert:\n",
    "nouns_ws = [ token.text for token in normalized_ws_doc if token.pos_ == 'NOUN']\n",
    "# Alle Nouns werden aus dem normalisierten Text herausgefiltert:\n",
    "verbs_ws = [ token.text for token in normalized_ws_doc if token.pos_ == 'VERB']\n",
    "# Alle Wörter werden als Tokentext abgespeichert\n",
    "words_ws = [ token.text for token in normalized_ws_doc]\n",
    "#Anzahl der Token umgewandelt in String und dann in Token\n",
    "number = len(nlp(normalized_ws_doc)) \n",
    "number = str(number)\n",
    "number = nlp(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc4446fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe zur Kontrolle\n",
    "#print(nouns_ws)\n",
    "#print(verbs_ws)\n",
    "#print(words_ws)\n",
    "#print (doc)\n",
    "#print (normalized_ws_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b078970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der 10 am häufigsten vorkommenden Nouns\n",
    "ten_nouns = Counter(nouns_ws).most_common(10)\n",
    "# Berechnung der 10 am häufigsten vorkommenden Verben\n",
    "ten_verbs = Counter(verbs_ws).most_common(10)\n",
    "#Berechnung der 10 am häufigsten vorkommenden Wörter\n",
    "ten_words = Counter(words_ws).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7328f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays werden initialisiert\n",
    "song_sent_score = []\n",
    "song_sent_label = []\n",
    "song_sent_subjectivity = []\n",
    "total_pos = []\n",
    "total_neg = []\n",
    "positive_words = []\n",
    "negative_words = []\n",
    "\n",
    "#Sentiment und Subjectivity wird dem Lied zugeordnet\n",
    "sentiment = doc._.blob.polarity\n",
    "sentiment = round(sentiment,2)\n",
    "subjectivity = doc._.blob.subjectivity\n",
    "subjectivity = round(subjectivity,2)\n",
    "\n",
    "#Sentimentscore wird verwendet um das Lied als positives oder negatives einzustufen\n",
    "if sentiment > 0:\n",
    "  sent_label = \"Positive\"\n",
    "else:\n",
    "  sent_label = \"Negative\"\n",
    "\n",
    "#Resultate werden den entsprechenden Kategorien zugeordnet\n",
    "song_sent_label.append(sent_label)\n",
    "song_sent_score.append(sentiment)\n",
    "song_sent_subjectivity.append(subjectivity)\n",
    "\n",
    "#Einzelne Tupel (Token + Sentiment) werden als positives oder negatives Wort geteilt\n",
    "for x in doc._.blob.sentiment_assessments.assessments:\n",
    "  if x[1] > 0:\n",
    "    positive_words.append(x[0][0])\n",
    "  elif x[1] < 0:\n",
    "    negative_words.append(x[0][0])\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "#Resultate werden den entsprechenden Kategorien zugeordnet\n",
    "total_pos.append(', '.join(set(positive_words)))\n",
    "total_neg.append(', '.join(set(negative_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39fe8b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fehlende Arrays werden erstellt\n",
    "total_nouns = []\n",
    "total_verbs = []\n",
    "total_words = []\n",
    "total_amount = []\n",
    "\n",
    "#Listen werden mit Panda als Basisdatei eingelesen\n",
    "liste = pd.read_csv(\"liste.csv\", index_col=\"Nr.\") #in der liste.csv muss nur \"Nr.\" stehen\n",
    "liste1 = pd.read_csv(\"liste1.csv\", index_col=\"Nr.\")\n",
    "\n",
    "#Liste wird mit Daten gefüllt\n",
    "liste [\"Häufigste Nouns\"]= ten_nouns\n",
    "liste [\"Häufigste Verben\"]= ten_verbs\n",
    "liste [\"Häufigste Wörter\"]= ten_words\n",
    "\n",
    "#Liste 1 wird mit Daten gefüllt\n",
    "liste1[\"Anzahl aller Token\"] = number\n",
    "liste1[\"Sentiment Score\"] = song_sent_score\n",
    "liste1[\"Sentiment Label\"] = song_sent_label\n",
    "liste1[\"Sentiment Subjectivity\"] = song_sent_subjectivity\n",
    "liste1[\"Positive Wörter\"] = total_pos\n",
    "liste1[\"Negative Wörter\"] = total_neg\n",
    "\n",
    "\n",
    "#Listen werden als CSV gespeichert\n",
    "liste.to_csv(\"Ergebnisse\\ergebnisse.csv\")\n",
    "liste1.to_csv(\"Ergebnisse\\sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc77ca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Häufigste Nouns</th>\n",
       "      <th>Häufigste Verben</th>\n",
       "      <th>Häufigste Wörter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nr.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(love, 25)</td>\n",
       "      <td>(come, 37)</td>\n",
       "      <td>(i, 64)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(body, 17)</td>\n",
       "      <td>(be, 28)</td>\n",
       "      <td>(be, 52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(baby, 14)</td>\n",
       "      <td>(follow, 6)</td>\n",
       "      <td>(on, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(lead, 6)</td>\n",
       "      <td>(discover, 6)</td>\n",
       "      <td>(come, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(shape, 6)</td>\n",
       "      <td>(talk, 4)</td>\n",
       "      <td>(my, 33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(day, 6)</td>\n",
       "      <td>(go, 3)</td>\n",
       "      <td>(in, 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(brand, 6)</td>\n",
       "      <td>(put, 3)</td>\n",
       "      <td>(love, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(magnet, 3)</td>\n",
       "      <td>(let, 3)</td>\n",
       "      <td>(and, 24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(heart, 3)</td>\n",
       "      <td>(push, 3)</td>\n",
       "      <td>(oh, 24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(night, 3)</td>\n",
       "      <td>(pull, 3)</td>\n",
       "      <td>(with, 22)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Häufigste Nouns Häufigste Verben Häufigste Wörter\n",
       "Nr.                                                  \n",
       "0        (love, 25)       (come, 37)          (i, 64)\n",
       "1        (body, 17)         (be, 28)         (be, 52)\n",
       "2        (baby, 14)      (follow, 6)         (on, 40)\n",
       "3         (lead, 6)    (discover, 6)       (come, 37)\n",
       "4        (shape, 6)        (talk, 4)         (my, 33)\n",
       "5          (day, 6)          (go, 3)         (in, 27)\n",
       "6        (brand, 6)         (put, 3)       (love, 25)\n",
       "7       (magnet, 3)         (let, 3)        (and, 24)\n",
       "8        (heart, 3)        (push, 3)         (oh, 24)\n",
       "9        (night, 3)        (pull, 3)       (with, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2d9aced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anzahl aller Token</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Sentiment Label</th>\n",
       "      <th>Sentiment Subjectivity</th>\n",
       "      <th>Positive Wörter</th>\n",
       "      <th>Negative Wörter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nr.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>705</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.51</td>\n",
       "      <td>sweet, love, first, fast, much, best, okay, new</td>\n",
       "      <td>slow, crazy, sour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Anzahl aller Token  Sentiment Score Sentiment Label  \\\n",
       "Nr.                                                       \n",
       "0                  705             0.32        Positive   \n",
       "\n",
       "     Sentiment Subjectivity                                  Positive Wörter  \\\n",
       "Nr.                                                                            \n",
       "0                      0.51  sweet, love, first, fast, much, best, okay, new   \n",
       "\n",
       "       Negative Wörter  \n",
       "Nr.                     \n",
       "0    slow, crazy, sour  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd14b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
